{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_stance_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9ZjLUvshPAUyA6EkU1Iqy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phillipinseoul/StanceDetection/blob/master/bert_stance_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBfTAnpRfSPZ"
      },
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5f6WGWOfkhu"
      },
      "source": [
        "# Set tensorflow version to 1.x\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqRpvHM54VUY"
      },
      "source": [
        "# Set up TPU environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX9FmTrufj4b"
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import run_classifier\n",
        "import run_classifier_with_tfhub\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyzekq604d48"
      },
      "source": [
        "# Prepare & Import BERT module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOWzgA2lfj-t"
      },
      "source": [
        "!rm -rf bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEk4bRMUfkDu"
      },
      "source": [
        "import sys\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "!test -d bert || git clone https://github.com/shalmolighosh/bert/\n",
        "if not 'bert' in sys.path:\n",
        "  sys.path += ['bert']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-waxO_SbfkMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1866d5ed-723f-43f2-ea05-2537d310bc06"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIhPHAc2gqFZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951e8f8e-62ec-4d34-eb74-fb3a5d9ad474"
      },
      "source": [
        "!ls gdrive/My\\ Drive/BERT/Data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Atheism  CC  FM  HC  LA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W468FIsU4j8W"
      },
      "source": [
        "# Prepare for training\n",
        "\n",
        "\n",
        "*   Specify task and download training data.\n",
        "* Specify BERT pretrained model\n",
        "* Specify GS bucket, create output directory for model checkpoints and eval results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2ICj_9Hi3m8"
      },
      "source": [
        "!gsutil help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BKG5B-9gqJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d732f672-9a59-4089-932f-06ac3a3500be"
      },
      "source": [
        "TASK = 'HC'\n",
        "assert TASK in ('MRPC', 'CoLA', 'Atheism','CC','HC','LA','FM','ALL'), 'Only (MRPC, CoLA) are demonstrated here.'\n",
        "\n",
        "# Download glue data.\n",
        "if TASK=='MRPC' or TASK=='CoLA':\n",
        "  ! test -d download_glue_repo || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git download_glue_repo\n",
        "  !python download_glue_repo/download_glue_data.py --data_dir='glue_data' --tasks=$TASK\n",
        "  TASK_DATA_DIR = 'glue_data/' + TASK\n",
        "elif TASK!='ALL':\n",
        "  TASK_DATA_DIR = 'gdrive/My\\ Drive/BERT/Data/' + TASK\n",
        "else:\n",
        "  TASK_DATA_DIR = 'gdrive/My\\ Drive/BERT/Data/'\n",
        "\n",
        "print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
        "!ls $TASK_DATA_DIR\n",
        "\n",
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "BERT_MODEL = 'uncased_L-24_H-1024_A-16'\n",
        "BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL\n",
        "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "!gsutil ls $BERT_PRETRAINED_DIR\n",
        "\n",
        "# BUCKET = 'bert-large-pair' #@param {type:\"string\"}\n",
        "BUCKET = 'bert-stance-detection'    # Changed to my own bucket in Google Cloud Storage\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/bert/models/{}/{}_new'.format(BUCKET,BERT_MODEL ,TASK)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Task data directory: gdrive/My\\ Drive/BERT/Data/HC *****\n",
            "test_preprocessed.csv  train_preprocessed.csv\n",
            "***** BERT pretrained directory: gs://cloud-tpu-checkpoints/bert/uncased_L-24_H-1024_A-16 *****\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-24_H-1024_A-16/bert_config.json\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-24_H-1024_A-16/bert_model.ckpt.data-00000-of-00001\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-24_H-1024_A-16/bert_model.ckpt.index\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-24_H-1024_A-16/bert_model.ckpt.meta\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-24_H-1024_A-16/checkpoint\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-24_H-1024_A-16/vocab.txt\n",
            "***** Model output directory: gs://bert-stance-detection/bert/models/uncased_L-24_H-1024_A-16/HC_new *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IHLR0SBgqOC"
      },
      "source": [
        "#!gsutil cp gs://bert-final/bert/models/Atheism/* gs://bert-large-pair/bert/models/uncased_L-24_H-1024_A-16/Atheism"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9Bp4uBK4ndv"
      },
      "source": [
        "# Setup task specific BERT model and TPU running configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4kzLDOo1aoq"
      },
      "source": [
        "import modeling\n",
        "import optimization\n",
        "import run_classifier\n",
        "import tokenization\n",
        "\n",
        "if TASK!='ALL':\n",
        "  TASK_DATA_DIR = 'gdrive/My Drive/BERT/Data/' + TASK\n",
        "else:\n",
        "  TASK_DATA_DIR = 'gdrive/My Drive/BERT/Data/'\n",
        "\n",
        "# Model Hyper Parameters\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "EVAL_BATCH_SIZE = 8\n",
        "PREDICT_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = \"11\"\n",
        "NUM_TRAIN_EPOCHS = int(NUM_TRAIN_EPOCHS)\n",
        "WARMUP_PROPORTION = 0.1\n",
        "MAX_SEQ_LENGTH = 128\n",
        "\n",
        "# Model configuration\n",
        "SAVE_CHECKPOINTS_STEPS = 1000\n",
        "ITERATIONS_PER_LOOP = 1000\n",
        "NUM_TPU_CORES = 8\n",
        "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
        "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
        "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
        "DO_LOWER_CASE = BERT_MODEL.startswith('uncased')\n",
        "\n",
        "processors = {\n",
        "  \"cola\": run_classifier.ColaProcessor,\n",
        "  \"mnli\": run_classifier.MnliProcessor,\n",
        "  \"mrpc\": run_classifier.MrpcProcessor,\n",
        "  \"hc\"  : run_classifier.SemProcessor,\n",
        "    \"atheism\" : run_classifier.SemProcessor,\n",
        "    \"fm\" : run_classifier.SemProcessor,\n",
        "    \"cc\" : run_classifier.SemProcessor,\n",
        "    \"la\" : run_classifier.SemProcessor,\n",
        "    \"all\" : run_classifier.SemProcessor\n",
        "}\n",
        "print(processors[TASK.lower()])\n",
        "\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)\n",
        "\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "\n",
        "if TASK == 'ALL':\n",
        "  train_examples = []\n",
        "  full_forms = {'HC' : 'hillary clinton', 'CC' : 'climate change is a concern','Atheism' : 'Atheism', 'LA' : 'Legalisation of Abortion', 'FM' : 'Feminist Movement'}\n",
        "  for key,value in full_forms.items():\n",
        "    processor = run_classifier.SemProcessor(use_pair=True, topic = value)\n",
        "    label_list = processor.get_labels()\n",
        "    train_examples += processor.get_train_examples(TASK_DATA_DIR+key)   \n",
        "else:\n",
        "  full_forms = {'HC' : 'hillary clinton', 'CC' : 'climate change is a concern','Atheism' : 'Atheism', 'LA' : 'Legalisation of Abortion', 'FM' : 'Feminist Movement'}\n",
        "  processor = processors[TASK.lower()](use_pair=False,\\\n",
        "                                       topic=full_forms[TASK])\n",
        "  label_list = processor.get_labels()\n",
        "  train_examples = processor.get_train_examples(TASK_DATA_DIR)\n",
        "\n",
        "print(\"Number of train examples :\",len(train_examples))\n",
        "\n",
        "\n",
        "num_train_steps = int(\n",
        "    len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Model function\n",
        "model_fn = run_classifier.model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=INIT_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=True,\n",
        "    use_one_hot_embeddings=True)\n",
        "\n",
        "# TPU Estimator\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    predict_batch_size = PREDICT_BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is2JFVkhgqRs"
      },
      "source": [
        "import csv\n",
        "\n",
        "\"\"\"Reads a tab separated value file.\"\"\"\n",
        "def read_csv(input_file, quotechar=None):\n",
        "  with tf.gfile.Open(input_file, \"r\") as f:\n",
        "    reader = reader = csv.reader(f)\n",
        "    lines = []\n",
        "    for line in reader:\n",
        "      if sys.version_info[0]==2:\n",
        "        line = list(unicode(cell, 'utf-8') for cell in line)\n",
        "      lines.append(line)\n",
        "    return lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHtSIC3F1Vkf"
      },
      "source": [
        "lines = read_csv(TASK_DATA_DIR+'/train_preprocessed.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9cI3M9OAufO"
      },
      "source": [
        "lines[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht43rBnJ4rTq"
      },
      "source": [
        "# Train the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k30x1P3c1VqR"
      },
      "source": [
        "print('MRPC/CoLA on BERT base model normally takes about 2-3 minutes. Please wait...')\n",
        "\n",
        "train_features = run_classifier.convert_examples_to_features(\n",
        "    train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(len(train_examples)))\n",
        "print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "\n",
        "train_input_fn = run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=True)\n",
        "\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print('***** Finished training at {} *****'.format(datetime.datetime.now()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5XiOkh577Vb"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RydbVVk6pPo"
      },
      "source": [
        "if TASK != 'ALL':\n",
        "  eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n",
        "else:\n",
        "  eval_examples = []\n",
        "  full_forms = {'HC' : 'hillary clinton', 'CC' : 'climate change is a concern','Atheism' : 'Atheism', 'LA' : 'Legalisation of Abortion', 'FM' : 'Feminist Movement'}\n",
        "  for key,value in full_forms.items():\n",
        "    processor = run_classifier.SemProcessor(use_pair=True, topic = value)\n",
        "    eval_examples += processor.get_dev_examples(TASK_DATA_DIR+key)   \n",
        "\n",
        "eval_features = run_classifier.convert_examples_to_features(\n",
        "    eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(len(eval_examples)))\n",
        "print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "\n",
        "# Evaluation will be slightly WRONG on the TPU because it will truncate the last batch.\n",
        "eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n",
        "\n",
        "eval_input_fn = run_classifier.input_fn_builder(\n",
        "    features=eval_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=True)\n",
        "\n",
        "result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "\n",
        "output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "  print(\"***** Eval results *****\")\n",
        "  for key in sorted(result.keys()):\n",
        "    print('  {} = {}'.format(key, str(result[key])))\n",
        "    writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-_fLbwz6pba"
      },
      "source": [
        "preds = estimator.predict(  \n",
        "    input_fn=eval_input_fn\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZf1eHc96pfz"
      },
      "source": [
        "all_preds = []\n",
        "for pred in preds:\n",
        "  all_preds.append(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH2U-y8e6plZ",
        "outputId": "1522686e-cf97-4ef2-cfe9-9c39ddf2b073"
      },
      "source": [
        "import numpy as np\n",
        "np.argmax(all_preds[0]['probabilities'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwj8y3ph1Vu-"
      },
      "source": [
        "test = eval_examples\n",
        "test[0].text_a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh8vujbD1V5r",
        "outputId": "90aab3cc-895f-4904-a3a5-72aa3990e3ae"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "matrix = np.array([[0,0,0],[0,0,0]])\n",
        "\n",
        "for i in range(len(all_preds)):\n",
        "  gold = int(test[i].label)\n",
        "  pred = np.argmax(all_preds[i]['probabilities'])\n",
        "  if gold<2:\n",
        "    matrix[gold][2]+=1\n",
        "  if pred < 2:\n",
        "    matrix[pred][1]+=1\n",
        "    if gold == pred:\n",
        "      matrix[gold][0]+=1\n",
        "  \n",
        "print(matrix)\n",
        "a = matrix[0][0]/(matrix[0][1]+matrix[0][2]+1e-5)\n",
        "b = matrix[1][0]/(matrix[1][1]+matrix[1][2]+1e-5)\n",
        "print(\"fscore - \",a+b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[172 295 172]\n",
            " [  0   0  45]]\n",
            "fscore -  0.3683083432910419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4praWBP7-lP5"
      },
      "source": [
        "labels_dict = [\"oppose\",\"support\",\"neutral\"]\n",
        "tweets = [\"tweet\"]+[t.text_a for t in test]\n",
        "gold_labels = [\"correct\"]+[labels_dict[int(t.label)] for t in test]\n",
        "pred_labels = [\"predicted\"]+[labels_dict[np.argmax(t['probabilities'])] for t in all_preds]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOqPGBMk-lUz"
      },
      "source": [
        "tweets[0],gold_labels[0],pred_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJJocgH5-lZW"
      },
      "source": [
        "# ex) Save the prediction result into \"HC.csv\"\n",
        "np.savetxt('{}.csv'.format(TASK), [p for p in zip(tweets, gold_labels, pred_labels)], delimiter='\\t', fmt='%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wye0v1Cx-leP",
        "outputId": "62b2b1b8-b0d4-4930-9442-e89932ffef90"
      },
      "source": [
        "!pwd      # Get current directory\n",
        "!ls       # Get contents"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "adc.json  bert\tgdrive\tHC.csv\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIgixIDT-li8"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"{}.csv\".format(TASK),sep='\\t')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOrNwZs4_fuS"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1RzM6ZT_fz0"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('HC.csv')    # ex) Download HC.csv which is in the current directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RVZlzZ4_f4P"
      },
      "source": [
        "df.to_csv('gdrive/My Drive/BERT/HC.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXWaYIc3BXrk"
      },
      "source": [
        "SAVE_DATA_DIR = 'gdrive/My Drive/BERT/'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}